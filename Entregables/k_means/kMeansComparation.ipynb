{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k, max_iterations=10000):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "\n",
    "    def initializeCentroids(self, data):\n",
    "        # Inicialización de centroides de manera aleatoria\n",
    "        np.random.seed(0)\n",
    "        indices = np.random.choice(data.shape[0], self.k, replace=False)\n",
    "        centroids = data[indices]\n",
    "        return centroids\n",
    "    \n",
    "    def initializeCentroidsFeatures(self, data, real_labels):\n",
    "        vectoreded_images = data.reshape(data.shape[0], -1)  # Aplanar las imágenes en vectores de características\n",
    "        UniqueLabels = np.unique(real_labels)\n",
    "\n",
    "        # Cálculo de características promedio por etiqueta\n",
    "        centroids = []\n",
    "        for label in UniqueLabels:\n",
    "            label_images = vectoreded_images[real_labels == label]\n",
    "            label_mean = np.mean(label_images, axis=0)\n",
    "            centroids.append(label_mean)\n",
    "\n",
    "        # Selección de los primeros K centroides iniciales\n",
    "        centroids = np.array(centroids)[:self.k]\n",
    "        return centroids\n",
    "\n",
    "    def AssignClusters(self, data):\n",
    "        distances = np.sqrt(((data[:, np.newaxis] - self.centroids) ** 2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        return labels\n",
    "\n",
    "    def UpdateCentroids(self, data):\n",
    "        # Actualización de los centroides como la media de los puntos asignados a cada clúster\n",
    "        centroids = np.zeros((self.k, data.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_data = data[self.labels == i]\n",
    "            if len(cluster_data) > 0:\n",
    "                centroids[i] = np.mean(cluster_data, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def fitRANDOM(self, data):\n",
    "        self.centroids = self.initializeCentroids(data)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.AssignClusters(data)\n",
    "            self.centroids = self.UpdateCentroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "            \n",
    "    def fitPreprocess(self, data, real_labels):\n",
    "        self.centroids = self.initializeCentroidsFeatures(data, real_labels)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.AssignClusters(data)\n",
    "            self.centroids = self.UpdateCentroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "\n",
    "    def predict(self, data):\n",
    "        labels = self.AssignClusters(data)\n",
    "        return labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfussionMatrix(true_labels, predicted_labels, num_classes):\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        confusion_matrix[true_label][predicted_label] += 1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareKmeans(X_train ,Y_train, X_test, Y_test, k = 10 ):\n",
    "    kmeansPre = KMeans(k)\n",
    "    kmeansR = KMeans(k)\n",
    "    \n",
    "    # Ajustar el modelo a los datos\n",
    "    kmeansPre.fitPreprocess(X_train, Y_train)\n",
    "    kmeansR.fitRANDOM(X_train)\n",
    "    \n",
    "    # Obtener las etiquetas asignadas a cada punto\n",
    "    predicted_labelsPre = kmeansPre.predict(X_test)\n",
    "    predicted_labelsR = kmeansR.predict(X_test)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    confusion_matrixPre = ConfussionMatrix(Y_test, predicted_labelsPre, num_classes=k)\n",
    "    confusion_matrixR = ConfussionMatrix(Y_test, predicted_labelsR, num_classes=k)\n",
    "   \n",
    "    # Imprimir la matriz de confusión\n",
    "    '''print(confusion_matrixPre)\n",
    "    print(confusion_matrixR)'''\n",
    "\n",
    "    # Calcular la precisión como la suma de las coincidencias diagonales dividida por el número total de puntos\n",
    "    accuracyPre = np.sum(np.max(confusion_matrixPre, axis=1)) / len(X_test)\n",
    "    accuracyR = np.sum(np.max(confusion_matrixR, axis=1)) / len(X_test)\n",
    "\n",
    "    # Imprimir la precisión\n",
    "    print(\"Precisión de clasificación con preprocesamiento: {:.2f}%\".format(accuracyPre * 100))\n",
    "    print(\"Precisión de clasificación con Random: {:.2f}%\".format(accuracyR * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArchive(fileName):\n",
    "    with open(fileName, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Elimina los caracteres de salto de línea y divide los valores por comas\n",
    "    data = [line.strip().split(',') for line in lines]\n",
    "\n",
    "    # Convierte la lista en una matriz de numpy\n",
    "    return np.array(data, dtype=int)\n",
    "\n",
    "dataTrain = readArchive('optdigits.tra')\n",
    "\n",
    "X_train = dataTrain[:, :64]\n",
    "Y_train = dataTrain[:, 64]\n",
    "\n",
    "dataTest = readArchive('optdigits.tes')\n",
    "X_test = dataTest[:, :64]\n",
    "Y_test = dataTest[: , 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de clasificación con preprocesamiento: 86.31%\n",
      "Precisión de clasificación con Random: 75.79%\n"
     ]
    }
   ],
   "source": [
    "compareKmeans(X_train,Y_train,X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
