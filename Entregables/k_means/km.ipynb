{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArchive(fileName):\n",
    "    with open(fileName, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Elimina los caracteres de salto de línea y divide los valores por comas\n",
    "    data = [line.strip().split(',') for line in lines]\n",
    "\n",
    "    # Convierte la lista en una matriz de numpy\n",
    "    return np.array(data, dtype=int)\n",
    "\n",
    "dataTrain = readArchive('optdigits.tra')\n",
    "\n",
    "X_train = dataTrain[:, :64]\n",
    "Y_train = dataTrain[:, 64]\n",
    "\n",
    "dataTest = readArchive('optdigits.tes')\n",
    "X_test = dataTest[:, :64]\n",
    "Y_test = dataTest[: , 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(true_labels, predicted_labels, num_classes):\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        confusion_matrix[true_label][predicted_label] += 1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_centroids_with_features(images, labels, num_clusters):\n",
    "    # Preprocesamiento de las imágenes\n",
    "    flattened_images = images.reshape(images.shape[0], -1)  # Aplanar las imágenes en vectores de características\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    # Cálculo de características promedio por etiqueta\n",
    "    centroids = []\n",
    "    for label in unique_labels:\n",
    "        label_images = flattened_images[labels == label]\n",
    "        label_mean = np.mean(label_images, axis=0)\n",
    "        centroids.append(label_mean)\n",
    "\n",
    "    # Selección de los primeros K centroides iniciales\n",
    "    centroids = np.array(centroids)[:num_clusters]\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[  0.   1.   0.   0.  83.   0.   0.   0.   0.  94.]\n",
      " [ 21.   0.   0.   3.   0.   1.   1.  95.  61.   0.]\n",
      " [150.   0.   9.   0.   0.   7.   3.   3.   4.   1.]\n",
      " [  0.   0.   8.   0.   0. 161.   9.   5.   0.   0.]\n",
      " [  0. 159.   1.   0.   0.   0.   6.   9.   6.   0.]\n",
      " [  0.   2.   2.   2.   0.  74.   0. 100.   2.   0.]\n",
      " [  0.   1.   1. 175.   0.   0.   0.   2.   1.   1.]\n",
      " [  0.   1.   0.   0.   0.   0. 166.   4.   8.   0.]\n",
      " [  1.   0. 118.   1.   0.   7.   1.  36.  10.   0.]\n",
      " [  0.   0.   3.   0.   0. 144.   5.   4.  24.   0.]]\n",
      "Precisión de clasificación: 75.79%\n"
     ]
    }
   ],
   "source": [
    "class KMeansRANDOM:\n",
    "    def __init__(self, k, max_iterations=10000):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "\n",
    "    def initialize_centroids(self, data):\n",
    "        # Inicialización de centroides de manera aleatoria\n",
    "        np.random.seed(0)\n",
    "        indices = np.random.choice(data.shape[0], self.k, replace=False)\n",
    "        centroids = data[indices]\n",
    "        return centroids\n",
    "\n",
    "    def assign_clusters(self, data):\n",
    "        # Asignación de puntos a clústeres según la distancia euclidiana\n",
    "        distances = np.sqrt(((data[:, np.newaxis] - self.centroids) ** 2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        return labels\n",
    "\n",
    "    def update_centroids(self, data):\n",
    "        # Actualización de los centroides como la media de los puntos asignados a cada clúster\n",
    "        centroids = np.zeros((self.k, data.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_data = data[self.labels == i]\n",
    "            if len(cluster_data) > 0:\n",
    "                centroids[i] = np.mean(cluster_data, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.centroids = self.initialize_centroids(data)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "\n",
    "    def predict(self, data):\n",
    "        labels = self.assign_clusters(data)\n",
    "        return labels\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Supongamos que tienes un conjunto de datos 'data' de dimensiones (n, d)\n",
    "# donde 'n' es el número de puntos y 'd' es el número de dimensiones.\n",
    "\n",
    "# Supongamos que tienes las etiquetas verdaderas de clase en la variable 'true_labels'\n",
    "true_labels = Y_test\n",
    "\n",
    "# Especifica el número de clústeres deseado\n",
    "k = 10\n",
    "\n",
    "# Crear instancia de la clase KMeans\n",
    "kmeans = KMeansRANDOM(k)\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Obtener las etiquetas asignadas a cada punto\n",
    "predicted_labels = kmeans.predict(X_test)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "confusion_matrix = calculate_confusion_matrix(true_labels, predicted_labels, num_classes=k)\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Calcular la precisión como la suma de las coincidencias diagonales dividida por el número total de puntos\n",
    "accuracy = np.sum(np.max(confusion_matrix, axis=1)) / len(X_test)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(\"Precisión de clasificación: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansPreprocess:\n",
    "    def __init__(self, k, max_iterations=1000):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        \n",
    "    def initialize_centroids_with_features(self, data, real_labels):\n",
    "        # Preprocesamiento de las imágenes\n",
    "        flattened_images = data.reshape(data.shape[0], -1)  # Aplanar las imágenes en vectores de características\n",
    "        unique_labels = np.unique(real_labels)\n",
    "\n",
    "        # Cálculo de características promedio por etiqueta\n",
    "        centroids = []\n",
    "        for label in unique_labels:\n",
    "            label_images = flattened_images[real_labels == label]\n",
    "            label_mean = np.mean(label_images, axis=0)\n",
    "            centroids.append(label_mean)\n",
    "\n",
    "        # Selección de los primeros K centroides iniciales\n",
    "        centroids = np.array(centroids)[:self.k]\n",
    "\n",
    "        return centroids\n",
    "\n",
    "    def assign_clusters(self, data):\n",
    "        # Asignación de puntos a clústeres según la distancia euclidiana\n",
    "        distances = np.sqrt(((data[:, np.newaxis] - self.centroids) ** 2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        return labels\n",
    "\n",
    "    def update_centroids(self, data):\n",
    "        # Actualización de los centroides como la media de los puntos asignados a cada clúster\n",
    "        centroids = np.zeros((self.k, data.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_data = data[self.labels == i]\n",
    "            if len(cluster_data) > 0:\n",
    "                centroids[i] = np.mean(cluster_data, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def fit(self, data, real_labels):\n",
    "        self.centroids = self.initialize_centroids_with_features(data, real_labels)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "\n",
    "    def predict(self, data):\n",
    "        labels = self.assign_clusters(data)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[176.   0.   0.   0.   2.   0.   0.   0.   0.   0.]\n",
      " [  0. 134.  21.   1.   0.   1.   3.   0.   7.  15.]\n",
      " [  1.   6. 150.   4.   0.   0.   0.   3.   9.   4.]\n",
      " [  0.   1.   1. 158.   0.   2.   0.   8.   5.   8.]\n",
      " [  0.   9.   0.   0. 159.   0.   0.   7.   6.   0.]\n",
      " [  0.   0.   0.   0.   1. 138.   1.   0.   0.  42.]\n",
      " [  1.   3.   0.   0.   0.   0. 176.   0.   1.   0.]\n",
      " [  0.   0.   0.   0.   1.   4.   0. 168.   6.   0.]\n",
      " [  0.  19.   1.   2.   0.   2.   1.   1. 138.  10.]\n",
      " [  0.   3.   0.   3.   5.   5.   0.   7.   3. 154.]]\n",
      "Precisión de clasificación: 86.31%\n"
     ]
    }
   ],
   "source": [
    "true_labels = Y_test\n",
    "\n",
    "# Especifica el número de clústeres deseado\n",
    "k = 10\n",
    "\n",
    "# Crear instancia de la clase KMeans\n",
    "kmeans = KMeansPreprocess(k)\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "kmeans.fit(X_train, Y_train)\n",
    "\n",
    "# Obtener las etiquetas asignadas a cada punto\n",
    "predicted_labels = kmeans.predict(X_test)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "confusion_matrix = calculate_confusion_matrix(true_labels, predicted_labels, num_classes=k)\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Calcular la precisión como la suma de las coincidencias diagonales dividida por el número total de puntos\n",
    "accuracy = np.sum(np.max(confusion_matrix, axis=1)) / len(X_test)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(\"Precisión de clasificación: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
